services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on: [zookeeper]
    ports: ["9092:9092"]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka-setup:
    image: confluentinc/cp-kafka:7.5.0
    depends_on: [kafka]
    command: >
      bash -c "kafka-topics --create --if-not-exists --topic stock-topic --partitions 1 --bootstrap-server kafka:29092 &&
               kafka-topics --create --if-not-exists --topic signals-topic --partitions 1 --bootstrap-server kafka:29092"

  # This app generates the raw prices
  producer_app:
    build: ./backend
    depends_on: 
      kafka-setup: { condition: service_completed_successfully }
    command: python Producer.py

  # This app saves raw prices to data.csv
  consumer_app:
    build: ./backend
    depends_on:
      kafka-setup: { condition: service_completed_successfully }
    volumes:
      - ./data:/data
    command: python Consumer.py

  # This app calculates Hurst/ADF and saves to signals.csv
  signal_worker:
    build: ./backend
    depends_on:
      kafka-setup: { condition: service_completed_successfully }
    volumes:
      - ./data:/data
    command: python SignalWorker.py

  # This app serves the CSVs to your React frontend
  backend_api:
    build: ./backend
    depends_on: [kafka]
    ports: ["8000:8000"]
    volumes:
      - ./data:/data
    command: uvicorn api:app --host 0.0.0.0 --port 8000
  
  frontend_app:
    build: ./frontend
    ports: ["3000:3000"]
    stdin_open: true
    environment:
      - CHOKIDAR_USEPOLLING=true
    depends_on: [backend_api]